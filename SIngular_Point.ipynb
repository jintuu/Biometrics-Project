{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "#from utils.poincare import calculate_singularities\n",
    "#from utils.segmentation import create_segmented_and_variance_images\n",
    "#from utils.normalization import normalize\n",
    "#from utils.gabor_filter import gabor_filter\n",
    "#from utils.frequency import ridge_freq\n",
    "#from utils import orientation\n",
    "#from utils.crossing_number import calculate_minutiaes\n",
    "from tqdm import tqdm\n",
    "#from utils.skeletonize import skeletonize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# orientation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "def calculate_angles(im, W, smoth=False):\n",
    "    \"\"\"\n",
    "    anisotropy orientation estimate, based on equations 5 from:\n",
    "    https://pdfs.semanticscholar.org/6e86/1d0b58bdf7e2e2bb0ecbf274cee6974fe13f.pdf\n",
    "    :param im:\n",
    "    :param W: int width of the ridge\n",
    "    :return: array\n",
    "    \"\"\"\n",
    "    j1 = lambda x, y: 2 * x * y\n",
    "    j2 = lambda x, y: x ** 2 - y ** 2\n",
    "    j3 = lambda x, y: x ** 2 + y ** 2\n",
    "\n",
    "    (y, x) = im.shape\n",
    "\n",
    "    sobelOperator = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "    ySobel = np.array(sobelOperator).astype(np.int)\n",
    "    xSobel = np.transpose(ySobel).astype(np.int)\n",
    "\n",
    "    result = [[] for i in range(1, y, W)]\n",
    "\n",
    "    Gx_ = cv.filter2D(im/125,-1, ySobel)*125\n",
    "    Gy_ = cv.filter2D(im/125,-1, xSobel)*125\n",
    "\n",
    "    for j in range(1, y, W):\n",
    "        for i in range(1, x, W):\n",
    "            nominator = 0\n",
    "            denominator = 0\n",
    "            for l in range(j, min(j + W, y - 1)):\n",
    "                for k in range(i, min(i + W , x - 1)):\n",
    "                    Gx = round(Gx_[l, k])  # horizontal gradients at l, k\n",
    "                    Gy = round(Gy_[l, k])  # vertial gradients at l, k\n",
    "                    nominator += j1(Gx, Gy)\n",
    "                    denominator += j2(Gx, Gy)\n",
    "\n",
    "            # nominator = round(np.sum(Gy_[j:min(j + W, y - 1), i:min(i + W , x - 1)]))\n",
    "            # denominator = round(np.sum(Gx_[j:min(j + W, y - 1), i:min(i + W , x - 1)]))\n",
    "            if nominator or denominator:\n",
    "                angle = (math.pi + math.atan2(nominator, denominator)) / 2\n",
    "                orientation = np.pi/2 + math.atan2(nominator,denominator)/2\n",
    "                result[int((j-1) // W)].append(angle)\n",
    "            else:\n",
    "                result[int((j-1) // W)].append(0)\n",
    "\n",
    "            # segment image\n",
    "            # focus_img = im[j:min(j + W, y - 1), i:min(i + W , x - 1)]\n",
    "            # segmentator = -1 if segmentator/W*W < np.max(focus_img)*\n",
    "\n",
    "    result = np.array(result)\n",
    "\n",
    "    if smoth:\n",
    "        result = smooth_angles(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def gauss(x, y):\n",
    "    ssigma = 1.0\n",
    "    return (1 / (2 * math.pi * ssigma)) * math.exp(-(x * x + y * y) / (2 * ssigma))\n",
    "\n",
    "\n",
    "def kernel_from_function(size, f):\n",
    "    kernel = [[] for i in range(0, size)]\n",
    "    for i in range(0, size):\n",
    "        for j in range(0, size):\n",
    "            kernel[i].append(f(i - size / 2, j - size / 2))\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def smooth_angles(angles):\n",
    "    \"\"\"\n",
    "    reference: https://airccj.org/CSCP/vol7/csit76809.pdf pg91\n",
    "    Practically, it is possible to have a block so noisy that the directional estimate is completely false.\n",
    "    This then causes a very large angular variation between two adjacent blocks. However, a\n",
    "    fingerprint has some directional continuity, such a variation between two adjacent blocks is then\n",
    "    representative of a bad estimate. To eliminate such discontinuities, a low-pass filter is applied to\n",
    "    the directional board.\n",
    "    :param angles:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    angles = np.array(angles)\n",
    "    cos_angles = np.cos(angles.copy()*2)\n",
    "    sin_angles = np.sin(angles.copy()*2)\n",
    "\n",
    "    kernel = np.array(kernel_from_function(5, gauss))\n",
    "\n",
    "    cos_angles = cv.filter2D(cos_angles/125,-1, kernel)*125\n",
    "    sin_angles = cv.filter2D(sin_angles/125,-1, kernel)*125\n",
    "    smooth_angles = np.arctan2(sin_angles, cos_angles)/2\n",
    "\n",
    "    return smooth_angles\n",
    "\n",
    "\n",
    "def get_line_ends(i, j, W, tang):\n",
    "    if -1 <= tang and tang <= 1:\n",
    "        begin = (i, int((-W/2) * tang + j + W/2))\n",
    "        end = (i + W, int((W/2) * tang + j + W/2))\n",
    "    else:\n",
    "        begin = (int(i + W/2 + W/(2 * tang)), j + W//2)\n",
    "        end = (int(i + W/2 - W/(2 * tang)), j - W//2)\n",
    "    return (begin, end)\n",
    "\n",
    "\n",
    "def visualize_angles(im, mask, angles, W):\n",
    "    (y, x) = im.shape\n",
    "    result = cv.cvtColor(np.zeros(im.shape, np.uint8), cv.COLOR_GRAY2RGB)\n",
    "    mask_threshold = (W-1)**2\n",
    "    for i in range(1, x, W):\n",
    "        for j in range(1, y, W):\n",
    "            radian = np.sum(mask[j - 1:j + W, i-1:i+W])\n",
    "            if radian > mask_threshold:\n",
    "                tang = math.tan(angles[(j - 1) // W][(i - 1) // W])\n",
    "                (begin, end) = get_line_ends(i, j, W, tang)\n",
    "                cv.line(result, begin, end, color=150)\n",
    "\n",
    "    cv.resize(result, im.shape, result)\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# poincare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import orientation\n",
    "import math\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def poincare_index_at(i, j, angles, tolerance):\n",
    "    \"\"\"\n",
    "    compute the summation difference between the adjacent orientations such that the orientations is less then 90 degrees\n",
    "    https://books.google.pl/books?id=1Wpx25D8qOwC&lpg=PA120&ots=9wRY0Rosb7&dq=poincare%20index%20fingerprint&hl=pl&pg=PA120#v=onepage&q=poincare%20index%20fingerprint&f=false\n",
    "    :param i:\n",
    "    :param j:\n",
    "    :param angles:\n",
    "    :param tolerance:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    cells = [(-1, -1), (-1, 0), (-1, 1),         # p1 p2 p3\n",
    "            (0, 1),  (1, 1),  (1, 0),            # p8    p4\n",
    "            (1, -1), (0, -1), (-1, -1)]          # p7 p6 p5\n",
    "\n",
    "    angles_around_index = [math.degrees(angles[i - k][j - l]) for k, l in cells]\n",
    "    index = 0\n",
    "    for k in range(0, 8):\n",
    "\n",
    "        # calculate the difference\n",
    "        difference = angles_around_index[k] - angles_around_index[k + 1]\n",
    "        if difference > 90:\n",
    "            difference -= 180\n",
    "        elif difference < -90:\n",
    "            difference += 180\n",
    "\n",
    "        index += difference\n",
    "\n",
    "    if 180 - tolerance <= index <= 180 + tolerance:\n",
    "        return \"loop\"\n",
    "    if -180 - tolerance <= index <= -180 + tolerance:\n",
    "        return \"delta\"\n",
    "    if 360 - tolerance <= index <= 360 + tolerance:\n",
    "        return \"whorl\"\n",
    "    return \"none\"\n",
    "\n",
    "\n",
    "def calculate_singularities(im, angles, tolerance, W, mask):\n",
    "    result = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "\n",
    "    # DELTA: RED, LOOP:ORAGNE, whorl:INK\n",
    "    colors = {\"loop\" : (0, 0, 255), \"delta\" : (0, 128, 255), \"whorl\": (255, 153, 255)}\n",
    "\n",
    "    for i in range(3, len(angles) - 2):             # Y\n",
    "        for j in range(3, len(angles[i]) - 2):      # x\n",
    "            # mask any singularity outside of the mask\n",
    "            mask_slice = mask[(i-2)*W:(i+3)*W, (j-2)*W:(j+3)*W]\n",
    "            mask_flag = np.sum(mask_slice)\n",
    "            if mask_flag == (W*5)**2:\n",
    "                singularity = poincare_index_at(i, j, angles, tolerance)\n",
    "                if singularity != \"none\":\n",
    "                    cv.rectangle(result, ((j+0)*W, (i+0)*W), ((j+1)*W, (i+1)*W), colors[singularity], 3)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #img = cv.imread('../test_img.png', 0)\n",
    "    #cv.imshow('original', img)\n",
    "    #angles = calculate_angles(img, 16, smoth=True)\n",
    "    #result = calculate_singularities(img, angles, 1, 16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmentation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "def normalise(img):\n",
    "    return (img - np.mean(img))/(np.std(img))\n",
    "\n",
    "\n",
    "def create_segmented_and_variance_images(im, w, threshold=.2):\n",
    "    \"\"\"\n",
    "    Returns mask identifying the ROI. Calculates the standard deviation in each image block and threshold the ROI\n",
    "    It also normalises the intesity values of\n",
    "    the image so that the ridge regions have zero mean, unit standard\n",
    "    deviation.\n",
    "    :param im: Image\n",
    "    :param w: size of the block\n",
    "    :param threshold: std threshold\n",
    "    :return: segmented_image\n",
    "    \"\"\"\n",
    "    (y, x) = im.shape\n",
    "    threshold = np.std(im)*threshold\n",
    "\n",
    "    image_variance = np.zeros(im.shape)\n",
    "    segmented_image = im.copy()\n",
    "    mask = np.ones_like(im)\n",
    "\n",
    "    for i in range(0, x, w):\n",
    "        for j in range(0, y, w):\n",
    "            box = [i, j, min(i + w, x), min(j + w, y)]\n",
    "            block_stddev = np.std(im[box[1]:box[3], box[0]:box[2]])\n",
    "            image_variance[box[1]:box[3], box[0]:box[2]] = block_stddev\n",
    "\n",
    "    # apply threshold\n",
    "    mask[image_variance < threshold] = 0\n",
    "\n",
    "    # smooth mask with a open/close morphological filter\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE,(w*2, w*2))\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_OPEN, kernel)\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # normalize segmented image\n",
    "    segmented_image *= mask\n",
    "    im = normalise(im)\n",
    "    mean_val = np.mean(im[mask==0])\n",
    "    std_val = np.std(im[mask==0])\n",
    "    norm_img = (im - mean_val)/(std_val)\n",
    "\n",
    "    return segmented_image, norm_img, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gabor-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The principle of gabor filtering is to modify the value of the pixels of an image, generally in order to\n",
    "improve its appearance. In practice, it is a matter of creating a new image using the pixel values\n",
    "of the original image, in order to select in the Fourier domain the set of frequencies that make up\n",
    "the region to be detected. The filter used is the Gabor filter with even symmetry and oriented at 0 degrees.\n",
    "\n",
    "The resulting image will be the spatial convolution of the original (normalized) image and one of\n",
    "the base filters in the direction and local frequency from the two directional and frequency maps\n",
    "https://airccj.org/CSCP/vol7/csit76809.pdf pg.91\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "def gabor_filter(im, orient, freq, kx=0.65, ky=0.65):\n",
    "    \"\"\"\n",
    "    Gabor filter is a linear filter used for edge detection. Gabor filter can be viewed as a sinusoidal plane of\n",
    "    particular frequency and orientation, modulated by a Gaussian envelope.\n",
    "    :param im:\n",
    "    :param orient:\n",
    "    :param freq:\n",
    "    :param kx:\n",
    "    :param ky:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    angleInc = 3\n",
    "    im = np.double(im)\n",
    "    rows, cols = im.shape\n",
    "    return_img = np.zeros((rows,cols))\n",
    "    \n",
    "\n",
    "    # Round the array of frequencies to the nearest 0.01 to reduce the\n",
    "    # number of distinct frequencies we have to deal with.\n",
    "    freq_1d = freq.flatten()\n",
    "    frequency_ind = np.array(np.where(freq_1d>0))\n",
    "    non_zero_elems_in_freq = freq_1d[frequency_ind]\n",
    "    non_zero_elems_in_freq = np.double(np.round((non_zero_elems_in_freq*100)))/100\n",
    "    unfreq = np.unique(non_zero_elems_in_freq)\n",
    "\n",
    "    # Generate filters corresponding to these distinct frequencies and\n",
    "    # orientations in 'angleInc' increments.\n",
    "    sigma_x = 1/unfreq*kx\n",
    "    sigma_y = 1/unfreq*ky\n",
    "    block_size = np.round(3*np.max([sigma_x,sigma_y]))\n",
    "    block_size = int(block_size)\n",
    "    array = np.linspace(-block_size,block_size,(2*block_size + 1))\n",
    "    x, y = np.meshgrid(array, array)\n",
    "\n",
    "    # gabor filter equation\n",
    "    reffilter = np.exp(-(((np.power(x,2))/(sigma_x*sigma_x) + (np.power(y,2))/(sigma_y*sigma_y)))) * np.cos(2*np.pi*unfreq[0]*x)\n",
    "    filt_rows, filt_cols = reffilter.shape\n",
    "    gabor_filter = np.array(np.zeros((180//angleInc, filt_rows, filt_cols)))\n",
    "\n",
    "    # Generate rotated versions of the filter.\n",
    "    for degree in range(0,180//angleInc):\n",
    "        rot_filt = scipy.ndimage.rotate(reffilter,-(degree*angleInc + 90),reshape = False)\n",
    "        gabor_filter[degree] = rot_filt\n",
    "\n",
    "    # Convert orientation matrix values from radians to an index value that corresponds to round(degrees/angleInc)\n",
    "    maxorientindex = np.round(180/angleInc)\n",
    "    orientindex = np.round(orient/np.pi*180/angleInc)\n",
    "    for i in range(0,rows//16):\n",
    "        for j in range(0,cols//16):\n",
    "            if(orientindex[i][j] < 1):\n",
    "                orientindex[i][j] = orientindex[i][j] + maxorientindex\n",
    "            if(orientindex[i][j] > maxorientindex):\n",
    "                orientindex[i][j] = orientindex[i][j] - maxorientindex\n",
    "\n",
    "    # Find indices of matrix points greater than maxsze from the image boundary\n",
    "    block_size = int(block_size)\n",
    "    valid_row, valid_col = np.where(freq>0)\n",
    "    finalind = \\\n",
    "        np.where((valid_row>block_size) & (valid_row<rows - block_size) & (valid_col>block_size) & (valid_col<cols - block_size))\n",
    "\n",
    "    for k in range(0, np.shape(finalind)[1]):\n",
    "        r = valid_row[finalind[0][k]]; c = valid_col[finalind[0][k]]\n",
    "        img_block = im[r-block_size:r+block_size + 1][:,c-block_size:c+block_size + 1]\n",
    "        return_img[r][c] = np.sum(img_block * gabor_filter[int(orientindex[r//16][c//16]) - 1])\n",
    "\n",
    "    gabor_img = 255 - np.array((return_img < 0)*255).astype(np.uint8)\n",
    "\n",
    "    return gabor_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# frequency.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.ndimage\n",
    "\n",
    "\n",
    "def frequest(im, orientim, kernel_size, minWaveLength, maxWaveLength):\n",
    "    \"\"\"\n",
    "    Based on https://pdfs.semanticscholar.org/ca0d/a7c552877e30e1c5d87dfcfb8b5972b0acd9.pdf pg.14\n",
    "    Function to estimate the fingerprint ridge frequency within a small block\n",
    "    of a fingerprint image.\n",
    "    An image block the same size as im with all values set to the estimated ridge spatial frequency.  If a\n",
    "    ridge frequency cannot be found, or cannot be found within the limits set by min and max Wavlength freqim is set to zeros.\n",
    "    \"\"\"\n",
    "    rows, cols = np.shape(im)\n",
    "    \n",
    "    # Find mean orientation within the block. This is done by averaging the\n",
    "    # sines and cosines of the doubled angles before reconstructing the angle again.\n",
    "    cosorient = np.cos(2*orientim) # np.mean(np.cos(2*orientim))\n",
    "    sinorient = np.sin(2*orientim) # np.mean(np.sin(2*orientim))\n",
    "    block_orient = math.atan2(sinorient,cosorient)/2\n",
    "    \n",
    "    # Rotate the image block so that the ridges are vertical\n",
    "    rotim = scipy.ndimage.rotate(im,block_orient/np.pi*180 + 90,axes=(1,0),reshape = False,order = 3,mode = 'nearest')\n",
    "\n",
    "    # Now crop the image so that the rotated image does not contain any invalid regions.\n",
    "    cropsze = int(np.fix(rows/np.sqrt(2)))\n",
    "    offset = int(np.fix((rows-cropsze)/2))\n",
    "    rotim = rotim[offset:offset+cropsze][:,offset:offset+cropsze]\n",
    "\n",
    "    # Sum down the columns to get a projection of the grey values down the ridges.\n",
    "    ridge_sum = np.sum(rotim, axis = 0)\n",
    "    dilation = scipy.ndimage.grey_dilation(ridge_sum, kernel_size, structure=np.ones(kernel_size))\n",
    "    ridge_noise = np.abs(dilation - ridge_sum); peak_thresh = 2;\n",
    "    maxpts = (ridge_noise < peak_thresh) & (ridge_sum > np.mean(ridge_sum))\n",
    "    maxind = np.where(maxpts)\n",
    "    _, no_of_peaks = np.shape(maxind)\n",
    "    \n",
    "    # Determine the spatial frequency of the ridges by dividing the\n",
    "    # distance between the 1st and last peaks by the (No of peaks-1). If no\n",
    "    # peaks are detected, or the wavelength is outside the allowed bounds, the frequency image is set to 0\n",
    "    if(no_of_peaks<2):\n",
    "        freq_block = np.zeros(im.shape)\n",
    "    else:\n",
    "        waveLength = (maxind[0][-1] - maxind[0][0])/(no_of_peaks - 1)\n",
    "        if waveLength>=minWaveLength and waveLength<=maxWaveLength:\n",
    "            freq_block = 1/np.double(waveLength) * np.ones(im.shape)\n",
    "        else:\n",
    "            freq_block = np.zeros(im.shape)\n",
    "    return(freq_block)\n",
    "\n",
    "\n",
    "def ridge_freq(im, mask, orient, block_size, kernel_size, minWaveLength, maxWaveLength):\n",
    "    # Function to estimate the fingerprint ridge frequency across a\n",
    "    # fingerprint image.\n",
    "    rows,cols = im.shape\n",
    "    freq = np.zeros((rows,cols))\n",
    "\n",
    "    for row in range(0, rows - block_size, block_size):\n",
    "        for col in range(0, cols - block_size, block_size):\n",
    "            image_block = im[row:row + block_size][:, col:col + block_size]\n",
    "            angle_block = orient[row // block_size][col // block_size]\n",
    "            if angle_block:\n",
    "                freq[row:row + block_size][:, col:col + block_size] = frequest(image_block, angle_block, kernel_size,\n",
    "                                                                               minWaveLength, maxWaveLength)\n",
    "\n",
    "    freq = freq*mask\n",
    "    freq_1d = np.reshape(freq,(1,rows*cols))\n",
    "    ind = np.where(freq_1d>0)\n",
    "    ind = np.array(ind)\n",
    "    ind = ind[1,:]\n",
    "    non_zero_elems_in_freq = freq_1d[0][ind]\n",
    "    medianfreq = np.median(non_zero_elems_in_freq) * mask\n",
    "\n",
    "    return medianfreq\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross_number.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def minutiae_at(pixels, i, j, kernel_size):\n",
    "    \"\"\"\n",
    "    https://airccj.org/CSCP/vol7/csit76809.pdf pg93\n",
    "    Crossing number methods is a really simple way to detect ridge endings and ridge bifurcations.\n",
    "    Then the crossing number algorithm will look at 3x3 pixel blocks:\n",
    "\n",
    "    if middle pixel is black (represents ridge):\n",
    "    if pixel on boundary are crossed with the ridge once, then it is a possible ridge ending\n",
    "    if pixel on boundary are crossed with the ridge three times, then it is a ridge bifurcation\n",
    "\n",
    "    :param pixels:\n",
    "    :param i:\n",
    "    :param j:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # if middle pixel is black (represents ridge)\n",
    "    if pixels[i][j] == 1:\n",
    "\n",
    "        if kernel_size == 3:\n",
    "            cells = [(-1, -1), (-1, 0), (-1, 1),        # p1 p2 p3\n",
    "                   (0, 1),  (1, 1),  (1, 0),            # p8    p4\n",
    "                  (1, -1), (0, -1), (-1, -1)]           # p7 p6 p5\n",
    "        else:\n",
    "            cells = [(-2, -2), (-2, -1), (-2, 0), (-2, 1), (-2, 2),                 # p1 p2   p3\n",
    "                   (-1, 2), (0, 2),  (1, 2),  (2, 2), (2, 1), (2, 0),               # p8      p4\n",
    "                  (2, -1), (2, -2), (1, -2), (0, -2), (-1, -2), (-2, -2)]           # p7 p6   p5\n",
    "\n",
    "        values = [pixels[i + l][j + k] for k, l in cells]\n",
    "\n",
    "        # count crossing how many times it goes from 0 to 1\n",
    "        crossings = 0\n",
    "        for k in range(0, len(values)-1):\n",
    "            crossings += abs(values[k] - values[k + 1])\n",
    "        crossings //= 2\n",
    "\n",
    "        # if pixel on boundary are crossed with the ridge once, then it is a possible ridge ending\n",
    "        # if pixel on boundary are crossed with the ridge three times, then it is a ridge bifurcation\n",
    "        if crossings == 1:\n",
    "            return \"ending\"\n",
    "        if crossings == 3:\n",
    "            return \"bifurcation\"\n",
    "\n",
    "    return \"none\"\n",
    "\n",
    "\n",
    "def calculate_minutiaes(im, kernel_size=3):\n",
    "    biniry_image = np.zeros_like(im)\n",
    "    biniry_image[im<10] = 1.0\n",
    "    biniry_image = biniry_image.astype(np.int8)\n",
    "\n",
    "    (y, x) = im.shape\n",
    "    result = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    colors = {\"ending\" : (150, 0, 0), \"bifurcation\" : (0, 150, 0)}\n",
    "\n",
    "    # iterate each pixel minutia\n",
    "    for i in range(1, x - kernel_size//2):\n",
    "        for j in range(1, y - kernel_size//2):\n",
    "            minutiae = minutiae_at(biniry_image, j, i, kernel_size)\n",
    "            if minutiae != \"none\":\n",
    "                cv.circle(result, (i,j), radius=2, color=colors[minutiae], thickness=2)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skeletonize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To facilitate extraction of minutiae the image must be skeletonized: a sequence of morphological\n",
    "erosion operations will reduce the thickness of the striations until the latter is equal to one pixel\n",
    "while maintaining the connectivity of the striations ( That is to say that the continuity of the\n",
    "striaes must be respected, holes must not be inserted). While some papers use Rosenfeld algorithm for its\n",
    "simplicity. [https://airccj.org/CSCP/vol7/csit76809.pdf pg.91] I used skimage Zha84 A fast parallel algorithm for\n",
    "thinning digital patterns, T. Y. Zhang and C. Y. Suen, Communications of the ACM, March 1984, Volume 27, Number 3.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "# from utils.crossing_number import calculate_minutiaes\n",
    "from skimage.morphology import skeletonize as skelt\n",
    "from skimage.morphology import thin\n",
    "def skeletonize(image_input):\n",
    "    \"\"\"\n",
    "    https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html\n",
    "    Skeletonization reduces binary objects to 1 pixel wide representations.\n",
    "    skeletonize works by making successive passes of the image. On each pass, border pixels are identified\n",
    "    and removed on the condition that they do not break the connectivity of the corresponding object.\n",
    "    :param image_input: 2d array uint8\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image = np.zeros_like(image_input)\n",
    "    image[image_input == 0] = 1.0\n",
    "    output = np.zeros_like(image_input)\n",
    "\n",
    "    skeleton = skelt(image)\n",
    "\n",
    "    \"\"\"uncomment for testing\"\"\"\n",
    "    # thinned = thin(image)\n",
    "    # thinned_partial = thin(image, max_iter=25)\n",
    "    #\n",
    "    # def minu_(skeleton, name):\n",
    "    #     cv.imshow('thin_'+name, output)\n",
    "    #     cv.bitwise_not(output, output)\n",
    "    #     minutias = calculate_minutiaes(output, kernel_size=5); cv.imshow('minu_'+name, minutias)\n",
    "    # # minu_(output, 'skeleton')\n",
    "    # # minu_(output, 'thinned')\n",
    "    # # minu_(output, 'thinned_partial')\n",
    "    # # cv.waitKeyEx()\n",
    "\n",
    "    output[skeleton] = 255\n",
    "    cv.bitwise_not(output, output)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def thinning_morph(image, kernel):\n",
    "    \"\"\"\n",
    "    Thinning image using morphological operations\n",
    "    :param image: 2d array uint8\n",
    "    :param kernel: 3x3 2d array unint8\n",
    "    :return: thin images\n",
    "    \"\"\"\n",
    "    thining_image = np.zeros_like(image)\n",
    "    img = image.copy()\n",
    "\n",
    "    while 1:\n",
    "        erosion = cv.erode(img, kernel, iterations = 1)\n",
    "        dilatate = cv.dilate(erosion, kernel, iterations = 1)\n",
    "\n",
    "        subs_img = np.subtract(img, dilatate)\n",
    "        cv.bitwise_or(thining_image, subs_img, thining_image)\n",
    "        img = erosion.copy()\n",
    "\n",
    "        done = (np.sum(img) == 0)\n",
    "\n",
    "        if done:\n",
    "          break\n",
    "\n",
    "    # shift down and compare one pixel offset\n",
    "    down = np.zeros_like(thining_image)\n",
    "    down[1:-1, :] = thining_image[0:-2, ]\n",
    "    down_mask = np.subtract(down, thining_image)\n",
    "    down_mask[0:-2, :] = down_mask[1:-1, ]\n",
    "    cv.imshow('down', down_mask)\n",
    "\n",
    "    # shift right and compare one pixel offset\n",
    "    left = np.zeros_like(thining_image)\n",
    "    left[:, 1:-1] = thining_image[:, 0:-2]\n",
    "    left_mask = np.subtract(left, thining_image)\n",
    "    left_mask[:, 0:-2] = left_mask[:, 1:-1]\n",
    "    cv.imshow('left', left_mask)\n",
    "\n",
    "    # combine left and down mask\n",
    "    cv.bitwise_or(down_mask, down_mask, thining_image)\n",
    "    output = np.zeros_like(thining_image)\n",
    "    output[thining_image < 250] = 255\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def fingerprint_pipline(input_img):\n",
    "    block_size = 16\n",
    "\n",
    "    # pipe line picture re https://www.cse.iitk.ac.in/users/biometrics/pages/111.JPG\n",
    "    # normalization -> orientation -> frequency -> mask -> filtering\n",
    "\n",
    "    # normalization - removes the effects of sensor noise and finger pressure differences.\n",
    "    normalized_img = normalise(input_img.copy())\n",
    "\n",
    "    # color threshold\n",
    "    # threshold_img = normalized_img\n",
    "    # _, threshold_im = cv.threshold(normalized_img,127,255,cv.THRESH_OTSU)\n",
    "    # cv.imshow('color_threshold', normalized_img); cv.waitKeyEx()\n",
    "\n",
    "    # ROI and normalisation\n",
    "    (segmented_img, normim, mask) = create_segmented_and_variance_images(normalized_img, block_size, 0.2)\n",
    "\n",
    "    # orientations\n",
    "    angles = calculate_angles(normalized_img, W=block_size, smoth=False)\n",
    "    orientation_img = visualize_angles(segmented_img, mask, angles, W=block_size)\n",
    "\n",
    "    # find the overall frequency of ridges in Wavelet Domain\n",
    "    freq = ridge_freq(normim, mask, angles, block_size, kernel_size=5, minWaveLength=5, maxWaveLength=15)\n",
    "\n",
    "    # create gabor filter and do the actual filtering\n",
    "    gabor_img = gabor_filter(normim, angles, freq)\n",
    "\n",
    "    # thinning oor skeletonize\n",
    "    thin_image = skeletonize(gabor_img)\n",
    "\n",
    "    # minutias\n",
    "    minutias = calculate_minutiaes(thin_image)\n",
    "\n",
    "    # singularities\n",
    "    singularities_img = calculate_singularities(thin_image, angles, 1, block_size, mask)\n",
    "\n",
    "    # visualize pipeline stage by stage\n",
    "    output_imgs = [input_img.astype('float32'), normalized_img.astype('float32'), segmented_img.astype('float32'), orientation_img.astype('float32'), gabor_img.astype('float32'), thin_image.astype('float32'), minutias.astype('float32'), singularities_img.astype('float32')]\n",
    "    for i in range(len(output_imgs)):\n",
    "        if len(output_imgs[i].shape) == 2:\n",
    "            output_imgs[i] = cv.cvtColor(output_imgs[i], cv.COLOR_GRAY2RGB)\n",
    "    results = np.concatenate([np.concatenate(output_imgs[:4], 1), np.concatenate(output_imgs[4:], 1)]).astype(np.uint8)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # open images\n",
    "    img_dir = './sample_inputs/*'\n",
    "    output_dir = './output/'\n",
    "    def open_images(directory):\n",
    "        images_paths = glob(directory)\n",
    "        return np.array([cv.imread(img_path,0) for img_path in images_paths])\n",
    "\n",
    "    images = open_images(img_dir)\n",
    "\n",
    "    # image pipeline\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i, img in enumerate(tqdm(images)):\n",
    "        results = fingerprint_pipline(img)\n",
    "        cv.imwrite(output_dir+str(i)+'.png', results)\n",
    "        # cv.imshow('image pipeline', results); cv.waitKeyEx()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread(\"103_3-p1f1b1dt1j8111l9p1u7e13sg1o90.png\", 0)\n",
    "cv.imshow(\"im\", image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = fingerprint_pipline(image)\n",
    "\n",
    "cv.imwrite(output_dir+'.png', results)\n",
    "cv.imshow('image pipeline', results)\n",
    "cv.waitKeyEx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
